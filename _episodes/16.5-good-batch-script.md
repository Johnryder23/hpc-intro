---
title: "Writing a Good Script"
teaching: 5
exercises: 5
questions:
- "How do we write a good job script."
objectives:
- "Understand writing robust scripts."
- "Writing scripts to allow parallel"
keypoints:
- "Parallelism"
---


Lets have a look at the script `array_sum.r`

```
{% include array_sum.r %}
```
{: .language-r}


```
num_cpus <- strtoi(Sys.getenv('SLURM_CPUS_PER_TASK', unset = "1")) 
```

Number of CPU's being used is fixed in the script. We can save time and reduce chances for making mistakes by replacing this static value with an enviroment variable. We can use the enviroment variable `SLURM_CPUS_PER_TASK`

```
num_cpus <- strtoi(Sys.getenv('SLURM_CPUS_PER_TASK')) 
```

This however, will not work if we choose to run the same peice of code on the login node, or on our local machine.
Generally it is best to diverge your codebase unless you have it under version control, so lets add some compatibility 

```
num_cpus <- strtoi(Sys.getenv('SLURM_CPUS_PER_TASK', unset = "1")) 
```

#### Verbose 

Now if the slurm variable is not set, 1 cpu will be used. (you could also use some other method of detecting CPUs, like `detectCores()`).

Having a printout of job progress is fine for an interactive terminal, but when you arn't seeing the updates in real time anyway, it's just bloat for your output files.

Let's add an option to mute the updates.

```
print_progress <- FALSE
```

```
if (print_progress && percent_complete%%1==0){

```

#### Reproduceability 

```
print_progress <- FALSE
slurm_array_task_id <- strtoi(Sys.getenv('SLURM_ARRAY_TASK_ID', unset = "-1"))
```
```
{% include array_sum2.r %}
```
{: .language-r}

{% include links.md %}
